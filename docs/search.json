[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Can AI enhance VR training? A systematic review of AI-VR training research.",
    "section": "",
    "text": "0.1 Welcome\nWelcome to the digital companion for our research poster:\nThis resource accompanies our conference presentation and provides:\nYou can use the navigation pane on the left (icon in the top-left corner on mobile) to explore the content.\n🧾 Download the Poster\n📧 Questions? Contact: defabiism1@university.edu",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Can AI enhance VR training? A systematic review of AI-VR training research.</span>"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Can AI enhance VR training? A systematic review of AI-VR training research.",
    "section": "",
    "text": "Can AI Enhance VR Training? A Systematic Review of AI-VR Training Research\n\n\n\nA downloadable version of the full poster\nExpanded background and methodology details\nReferences in APA format with citation support",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Can AI enhance VR training? A systematic review of AI-VR training research.</span>"
    ]
  },
  {
    "objectID": "01-background.html",
    "href": "01-background.html",
    "title": "2  Background",
    "section": "",
    "text": "2.1 An Introduction to AI-VR Training Programs\nVR is an effective method for organizational training, as it allows trainees to experience situations that cannot be lived in the real world due to time constraints, physical inaccessibility, dangers in the real situation, or ethical issues (Freina & Ott, 2015). Meta-analyses have further demonstrated the effectiveness of VR training, finding that VR training is more effective over alternative training methods in both specific (F.-Q. Chen et al., 2020; Haque & Srinivasan, 2006; Howard & Gutworth, 2020) and general (Howard et al., 2021) training modalities. AI has already found benefits in traditional learning platforms, specifically aiding in personalization, tutoring, and evaluation of e-learning platforms. Recently, researchers have begun combining similar AI applications with VR training programs. Before diving into AI-VR training, it is important to first understand VR and AI separately.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "02-research_questions.html",
    "href": "02-research_questions.html",
    "title": "3  Research Questions",
    "section": "",
    "text": "3.1 Research Question 1: Are the current VR and AI training programs utilizing best practices from the science of training?|",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Research Questions</span>"
    ]
  },
  {
    "objectID": "02-research_questions.html#research-question-1-are-the-current-vr-and-ai-training-programs-utilizing-best-practices-from-the-science-of-training",
    "href": "02-research_questions.html#research-question-1-are-the-current-vr-and-ai-training-programs-utilizing-best-practices-from-the-science-of-training",
    "title": "3  Research Questions",
    "section": "",
    "text": "3.1.1      1a. Are learning objectives created and clarified to the reader?\nLearning objectives should consist of descriptions of what trainers want to see trainees learn as a function of the training program (Ford, 2020). Good learning objectives highlight what a trainee should show they have accomplished as a result of the training. Learning objectives should be clarified to the extent that they provide a behavior, condition, and criterion (Ford, 2020). In this sense, a behavior refers to an objective that displays evidence of learning the desired training capability. When stating behaviors, trainers typically use verbs to describe observable actions. For example, intellectual problem-solving skills, a behavior could be specified as “discriminates by matching problems with solutions” (Ford, 2020). A condition refers to the various factors present when assessing the desired capability. Examples of conditions may include materials or tools provided to the learner when performing the task, restrictions imposed on the learner during the task, or even physical / environmental conditions induced during the task (Ford, 2020). The criterion refers to a set threshold or standard for acceptable performance on the learning task (Ford, 2020). A good criterion specifies the degree of performance necessary in order to complete the training task.\nAn example learning objective for a session designed to train teachers on how to use a new online assessment tool could be: “Given an online assessment creation tool (condition), teachers should be able to create (behavior) a 10-item quiz within 15 minutes (criterion).” In this example, the condition is a circumstance in which trainees are provided with a specific tool (online assessment creation tool), the behavior is the creation of a quiz, and the criterion is the creation of 10-item quiz within the time limit. Good learning objectives are important to any training program, as it provides a roadmap for planning the training and clearly communicates expectations to trainees (Ford, 2020).\n\n\n3.1.2      1b. Is the training delivered in a way that builds trainees’ belief in their ability to learn and display trained skills (self-efficacy).\nResearch has found that self-efficacy boosts trainee motivation (Colquitt et al., 2000; Tracey et al., 2001), and motivation to learn is positively linked with increased learning outcomes and trainee satisfaction (Klein et al., 2006; Tracey et al., 2001). Salas et al. (2012) notes that building self-efficacy is an important component of the training process, as it puts trainees into a learning mindset. With this in mind, AI-VR training programs should contain elements that boost self-efficacy.\n\n\n3.1.3      1c. Does the training encourage trainees to participate in training to learn rather than to appear capable (promotes a learning orientation).\nSimilar to building self-efficacy, promoting a learning orientation is integral to fostering the right trainee mindset (Salas et al., 2012). Those who engage in training with a learning orientation are found to engage in more effortful learning (Fisher & Ford, 1998), utilize adaptive metacognitive strategies (Ford et al., 1998), remain focused on the training task after receiving feedback, and even display higher learning outcomes (Ford, 2014; Phillips & Gully, 1997). Furthermore, on the opposite side of the spectrum, trainees with a performance orientation may sacrifice engagement and learning outcomes in an effort to get a higher ‘score’. With the plethora of benefits afforded by utilizing a learning orientation rather than a performance orientation in training, the promotion of a learning orientation in training participants is vital to positive learning outcomes. To support a learning orientation in any training, the program’s design features should promote long-term changes in comprehension, understanding, and skills rather than place emphasis on trainee performance (Ford, 2020; Soderstrom & Bjork, 2015).\n\n\n3.1.4      1d. Does the training engage trainees and build their interest?\nBy building interest and fostering trainee engagement, training programs can boost a trainee’s motivation to learn (Salas et al., 2012). This is particularly important, as trainee motivation can boost learning outcomes and trainee reactions (Baldwin et al., 1991; Tannenbaum et al., 1991). Similar to building self-efficacy and promoting a learning orientation, training programs that boost trainee motivation place trainees into a learning mindset (Salas et al., 2012). While some features (e.g. individual traits, work environment) cannot so easily be changed to boost motivation, modifying features of an AI-VR training program is something that researchers have a vast amount of control over.\n\n\n3.1.5      1e. Does the training utilize a valid training strategy and design? This involves providing information, giving demonstrations of good and bad | | behaviors, allowing opportunities to practice, and providing meaningful feedback.\nTraining programs should contain a valid training strategy and design, as these elements are essential to learning outcomes, especially in areas where trainees are experiencing difficulty (Salas et al., 2012). Historically, businesses have mostly relied on information and demonstration components when conducting organizational trainings (Patel, 2010). However, Salas et al. (2012) points out that both practice and effective feedback are crucial components for learning outcomes. Because VR is safe both physically and as a mental safe space (Howard & Gutworth, 2020), and because AI can facilitate meaningful feedback (Kiyasseh et al., 2023), AI-VR training programs are poised to provide effective training strategies. Whether they currently do is something that this research question hopes to discover.\n\n\n3.1.6      1f. Does the training allow trainees to use the same cognitive processes that they will have to in the environment this learning should transfer | to?\nTrainings that utilize the same cognitive processes as those used in the transfer environment not only increase successful transfer outcomes – they also increase sustained levels of transfer overtime (Schmidt & Bjork, 1992). In other words, training that utilize the same cognitive processes as the transfer environment help trainees 1. Successfully transfer their skills, and 2. Sustain those skills longterm. Salas et al. (2012) notes that this is often due to an added level of challenge that this implementation brings to training programs. Increased levels of difficulty brought upon by this implementation allow trainees to engage in deep learning mechanisms that encourage skill mastery and long-term transfer.\n\n\n3.1.7      1g. Does the training keep trainees’ attention by allowing trainees to monitor their progress toward goals?\nTraining programs that utilize elements that facilitate progress monitoring encourage self-regulation among trainees. In this sense, self-regulation refers to a trainee’s ability to self-monitor their learning and performance in relation to the training goal, and the ability to adjust learning efforts as needed (Salas et al., 2012). Research has shown promising effects of self-regulation on both improved trainee focus (Sitzmann & Ely, 2010) and increased learning outcomes (Berthold et al., 2007; Sitzmann et al., 2009), suggesting that progress-monitoring elements could be a beneficial addition to training (Salas, 2012). The many design features offered by AI-VR training programs (sensory cues, visual user-interfaces, etc.) allow for creative and unique goal-monitoring implementations.\n\n\n3.1.8      1h. Does the training encourage trainees to make errors?\nError encouragement is an important component of any training program not only because errors are a natural occurrence in any job, but also because it teaches error management skills that result in increased coping skills and performance (Frese et al., 1991). Salas et al. (2012) recommends error encourage particularly for complex cognitive tasks, but AI-VR training programs also have the added capability of encouraging errors in training environments that, in the real world, would be unsafe and risky. With this in mind, AI-VR training programs can facilitate error encouragement on a level that traditional training programs cannot reach.\n\n\n3.1.9      1i. Does the training provide sufficient structure to trainees when allowing them to make decisions about their learning experience?\nSalas et al. (2012) notes that training programs should, to some degree, individualize the training experience for trainees. Trainees should have as much freedom in their experience as a training program can feasibly allow without detracting from learning outcomes. Training programs must have sufficient structure to facilitate user control and individualized learning experiences, as recent research has demonstrated the effectiveness of learner control on both learning processes and outcomes (Sorgenfrei & Smolnik, 2016).\nSufficient learner control can be achieved in a variety of ways. Sorgenfrei & Smolnik (2016) highlight several methods researchers can use to influence learner control in e-learning training programs. First, researchers can provide control over the timing and pacing of instructional events. This form of learner control allows trainees to learn somewhat asynchronously, as they can control the pace of their learning process. Second, trainees could benefit from having control over the training location, which can be easily manipulated in an e-learning environment. Third, control over navigation and design allows trainees to control the sequence and order of learning material. Fourth, control over interactions allows trainees to control the degree in which they collaborate and work with other trainees during the training process. Last, control over content and task selection allows trainees to choose the content that they wish to learn. In their literature review, Sorgenfrei & Smolnik (2016) found that, despite minimal (or sometimes negative) effects of learner control on learner processes, cognitive and affective learning outcomes were enhanced across a variety of studies.\nIn recent years, research has demonstrated that AI is particularly effective at individualizing learning experiences, utilizing concepts such as decision trees to guide unique learning experiences (Matzavela & Alepis, 2021; Zhou et al., 2017). This, combined with VR’s advanced input hardware and capability in allowing free user movement, speech, and interactivity (Howard et al., 2021; Howard & Gutworth, 2020) poises AI-VR training programs to be able to allow for more decision-making in the learning experience while still maintaining the level of structure needed to not detract from learning outcomes.\n\n\n3.1.10      1j. Does the training simulation increase psychological fidelity (e.g. job-relevant, technology used fits the task)?\nPsychological fidelity, in a training context, refers to the extent that the training program places participants into a similar psychological state as what would be felt in the transfer environment (Howard et al., 2021). Salas et al. (2012) notes that increasing psychological fidelity enhances the training content’s relevance for job performance. In AI-VR training programs, psychological fidelity encapsulates more than the utilization of similar cognitive processes – it also involves a heavy emphasis towards increasing levels of immersion and presence within the simulation (Howard et al., 2021).\n\n\n3.1.11      1k. Does the training use established learning / outcome taxonomies (e.g. affective, cognitive, and/or behavioral indicators).\nLearning and development fields have a plethora of existing evaluation archetypes that are well received by scholars and practitioners alike. Kirkpatrick & Kirkpatrick (1994) evaluation model is a popular evaluation framework that involves measuring trainee reactions, learning, behaviors, and results. Kirkpatrick & Kirkpatrick (1994) considered these measurements to be ordinal, meaning that behavioral outcomes should not be measured until reaction and learning-based outcomes are assessed. Although Kirkpatrick & Kirkpatrick (1994)’s model does have its limitations (see Salas et al., 2012), it provides several useful evaluation comparisons and is widely used by a variety of organizations today.\nAnother widely popularized evaluation model comes from Kraiger et al. (1993), who identified three notable evaluation metrics: affective, cognitive, and behavioral outcomes. The model is considered to have two main focal points. First, when developing the training program, trainers should identify the purpose for evaluation in a clear and concise manner. Only after the purpose is identified should trainers decide on the actual affective, cognitive, or behavioral evaluation components. This process helps bring clarity to the training’s purpose, and lets trainers better tailor learning outcomes to the actual purpose of the training.\nThe second focal point of this model relies on precision: the measures used should match the intended outcome of the training. In other words, if a training is designed to measure fire-safety outcomes (see, for example, Truong et al., 2022), the training should not utilize a simple multiple choice test. Instead, the measurements used should align with the actual affective, cognitive, or behavioral outcome being taught. For example, when training employees on fire-safety outcomes, Kraiger et al. (1993)’s model would suggest measuring this with a simulated fire scenario. When it comes to using precise measurements, AI-VR training programs are poised to perform exceptionally well, as VR creates a safe space in which trainees can participate in various scenarios that psychologically immerses them in the experience (Howard et al., 2021).\nFurthermore, the law of accelerating returns creates issues with advancing previous research. The next technological advancement is always around the corner, meaning that it’s not long before researchers abandon current tech and move onto something new. However, before moving on and building on prior research, it is important to make sure that current studies are properly testing the incremental benefits of technologies that have already been added. In this case, it is important for researchers to ensure that AI is adding value to the VR training experience before implementing the “next big thing”. Therefore, it is critical that research studies compare AI-VR to VR trainings, and that they have adequate sample sizes to generalize results.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Research Questions</span>"
    ]
  },
  {
    "objectID": "02-research_questions.html#research-question-2-are-current-studies-on-ai-enhanced-vr-training-programs-utilizing-a-proper-control-group",
    "href": "02-research_questions.html#research-question-2-are-current-studies-on-ai-enhanced-vr-training-programs-utilizing-a-proper-control-group",
    "title": "3  Research Questions",
    "section": "3.2 Research Question 2: Are current studies on AI-enhanced VR training programs utilizing a proper control group?",
    "text": "3.2 Research Question 2: Are current studies on AI-enhanced VR training programs utilizing a proper control group?\nA proper control group is necessary in order to determine whether or not AI is actually adding any incremental benefits to the VR training experience. This relies on the ability to make direct comparisons between AI-VR and VR-only training programs. Therefore, for the context of this research question, a proper control group refers to a VR-only (no AI component) training group.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Research Questions</span>"
    ]
  },
  {
    "objectID": "02-research_questions.html#research-question-3-do-current-studies-on-ai-enhanced-vr-training-programs-have-a-sufficient-number-of-people-to-make-inferences-about-their-effectiveness",
    "href": "02-research_questions.html#research-question-3-do-current-studies-on-ai-enhanced-vr-training-programs-have-a-sufficient-number-of-people-to-make-inferences-about-their-effectiveness",
    "title": "3  Research Questions",
    "section": "3.3 Research Question 3: Do current studies on AI-enhanced VR training programs have a sufficient number of people to make inferences about their effectiveness?",
    "text": "3.3 Research Question 3: Do current studies on AI-enhanced VR training programs have a sufficient number of people to make inferences about their effectiveness?\nSample sizes often vary across studies, and many researchers use unique formulas to determine sample sizes across various statistics and methodologies (Milton, 1986; Schoenfeld, 1983; see, for example, Taherdoost, 2017). Because ideal sample sizes vary across research studies, no threshold will be set prior to reading articles. Instead, each research article’s sample size will be assessed on a case-by-case basis. Articles that have adequate sample sizes will have a number of participants that are adequate for their chosen research methodology and statistical formula. Furthermore, the research design and statistical formulas used should be those that are capable of making inferences about any particular findings effect.\nOnce the previous questions have been answered, it will be possible to analyze the preliminary findings of AI-enhanced VR research.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Research Questions</span>"
    ]
  },
  {
    "objectID": "02-research_questions.html#research-question-4-what-are-the-preliminary-findings-does-adding-ai-to-vr-training-result-in-a-better-experience-for-the-trainee-greater-learning-or-better-on-the-job-performance-than-regular-vr-training",
    "href": "02-research_questions.html#research-question-4-what-are-the-preliminary-findings-does-adding-ai-to-vr-training-result-in-a-better-experience-for-the-trainee-greater-learning-or-better-on-the-job-performance-than-regular-vr-training",
    "title": "3  Research Questions",
    "section": "3.4 Research Question 4: What are the preliminary findings: Does adding AI to VR training result in a better experience for the trainee, greater learning, or better on the job performance than regular VR training?",
    "text": "3.4 Research Question 4: What are the preliminary findings: Does adding AI to VR training result in a better experience for the trainee, greater learning, or better on the job performance than regular VR training?\nWith research burgeoning on AI-VR training, and with contracts as large as $20 million being given towards organizational VR training research (Talespin, 2022), it is of immense scientific and practical importance that each of these research questions are answered. With this in mind, a systematic literature review could greatly benefit AI-VR research, as it can be the first literature review to provide an overview of what AI-VR training research is doing right and where there is room for improvement. Rapid advancements in technology (Butler, 2016) make it is crucial to consolidate current research into a single meta-synthesis before current technology becomes outdated and new research begins stacking the latest innovations onto untested technologies. AI-VR training research is interdisciplinary, making a meta-synthesis very informative for several fields. The following systematic review offers a comprehensive analysis of the current state of AI-VR training research. Specifically, this literature review aims to determine the degree to which AI-VR training research follows best practices, whether AI-VR training research utilizes a proper control group and sample size, and, if so, whether or not the preliminary findings support AI’s inclusion in VR training research.\n\n\n\n\nBaldwin, T. T., Magjuka, R. J., & Loher, B. T. (1991). The perils of participation: Effects of choice of training on trainee motivation and learning. Personnel Psychology, 44(1), 51–65.\n\n\nBerthold, K., Nückles, M., & Renkl, A. (2007). Do learning protocols support learning strategies and outcomes? The role of cognitive and metacognitive prompts. Learning and Instruction, 17(5), 564–577.\n\n\nButler, D. (2016). Tomorrow’s world: Technological change is accelerating today at an unprecedented speed and could create a world we can barely begin to imagine. Nature, 530(7591), 398–402.\n\n\nColquitt, J. A., LePine, J. A., & Noe, R. A. (2000). Toward an integrative theory of training motivation: A meta-analytic path analysis of 20 years of research. Journal of Applied Psychology, 85(5), 678.\n\n\nFisher, S. L., & Ford, J. K. (1998). Differential effects of learner effort and goal orientation on two learning outcomes. Personnel Psychology, 51(2), 397–420.\n\n\nFord, J. K. (2014). Improving training effectiveness in work organizations. Psychology Press.\n\n\nFord, J. K. (2020). Learning in organizations: An evidence-based approach. Routledge.\n\n\nFord, J. K., Smith, E. M., Weissbein, D. A., Gully, S. M., & Salas, E. (1998). Relationships of goal orientation, metacognitive activity, and practice strategies with learning outcomes and transfer. Journal of Applied Psychology, 83(2), 218.\n\n\nFrese, M., Brodbeck, F., Heinbokel, T., Mooser, C., Schleiffenbaum, E., & Thiemann, P. (1991). Errors in training computer skills: On the positive function of errors. Human-Computer Interaction, 6(1), 77–93.\n\n\nHoward, M. C., & Gutworth, M. B. (2020). A meta-analysis of virtual reality training programs for social skill development. Computers & Education, 144, 103707.\n\n\nHoward, M. C., Gutworth, M. B., & Jacobs, R. R. (2021). A meta-analysis of virtual reality training programs. Computers in Human Behavior, 121, 106808.\n\n\nKirkpatrick, D. L., & Kirkpatrick, J. D. (1994). Evaluating programs: The four levels. Berrett-Koechler, San Francisco, CA.\n\n\nKiyasseh, D., Laca, J., Haque, T. F., Miles, B. J., Wagner, C., Donoho, D. A., Anandkumar, A., & Hung, A. J. (2023). A multi-institutional study using artificial intelligence to provide reliable and fair feedback to surgeons. Communications Medicine, 3(1), 42.\n\n\nKlein, H. J., Noe, R. A., & Wang, C. (2006). Motivation to learn and course outcomes: The impact of delivery mode, learning goal orientation, and perceived barriers and enablers. Personnel Psychology, 59(3), 665–702.\n\n\nKraiger, K., Ford, J. K., & Salas, E. (1993). Application of cognitive, skill-based, and affective theories of learning outcomes to new methods of training evaluation. Journal of Applied Psychology, 78(2), 311.\n\n\nMatzavela, V., & Alepis, E. (2021). Decision tree learning through a predictive model for student academic performance in intelligent m-learning environments. Computers and Education: Artificial Intelligence, 2, 100035.\n\n\nMilton, S. (1986). A sample size formula for multiple regression studies. Public Opinion Quarterly, 50(1), 112–118.\n\n\nPatel, L. (2010). ASTD state of the industry report 2010. American Society for Training & Development.\n\n\nPhillips, J. M., & Gully, S. M. (1997). Role of goal orientation, ability, need for achievement, and locus of control in the self-efficacy and goal–setting process. Journal of Applied Psychology, 82(5), 792.\n\n\nSalas, E., Tannenbaum, S. I., Kraiger, K., & Smith-Jentsch, K. A. (2012). The science of training and development in organizations: What matters in practice. Psychological Science in the Public Interest, 13(2), 74–101.\n\n\nSchmidt, R. A., & Bjork, R. A. (1992). New conceptualizations of practice: Common principles in three paradigms suggest new concepts for training. Psychological Science, 3(4), 207–218.\n\n\nSchoenfeld, D. A. (1983). Sample-size formula for the proportional-hazards regression model. Biometrics, 499–503.\n\n\nSitzmann, T., Bell, B. S., Kraiger, K., & Kanar, A. M. (2009). A multilevel analysis of the effect of prompting self-regulation in technology-delivered instruction. Personnel Psychology, 62(4), 697–734.\n\n\nSitzmann, T., & Ely, K. (2010). Sometimes you need a reminder: The effects of prompting self-regulation on regulatory processes, learning, and attrition. Journal of Applied Psychology, 95(1), 132.\n\n\nSoderstrom, N. C., & Bjork, R. A. (2015). Learning versus performance: An integrative review. Perspectives on Psychological Science, 10(2), 176–199.\n\n\nSorgenfrei, C., & Smolnik, S. (2016). The effectiveness of e-learning systems: A review of the empirical literature on learner control. Decision Sciences Journal of Innovative Education, 14(2), 154–184.\n\n\nTaherdoost, H. (2017). Determining sample size; how to calculate survey sample size. International Journal of Economics and Management Systems, 2.\n\n\nTalespin. (2022). Available at https://www.talespin.com/.\n\n\nTannenbaum, S. I., Mathieu, J. E., Salas, E., & Cannon-Bowers, J. A. (1991). Meeting trainees’ expectations: The influence of training fulfillment on the development of commitment, self-efficacy, and motivation. Journal of Applied Psychology, 76(6), 759.\n\n\nTracey, J. B., Hinkin, T. R., Tannenbaum, S., & Mathieu, J. E. (2001). The influence of individual characteristics and the work environment on varying levels of training outcomes. Human Resource Development Quarterly, 12(1), 5–23.\n\n\nTruong, H., Qi, D., Ryason, A., Sullivan, A. M., Cudmore, J., Alfred, S., Jones, S. B., Parra, J. M., De, S., & Jones, D. B. (2022). Does your team know how to respond safely to an operating room fire? Outcomes of a virtual reality, AI-enhanced simulation training. Surgical Endoscopy, 1–9.\n\n\nZhou, T. F., Pan, Y. Q., & Huang, L. R. (2017). Research on personalized e-learning based on decision tree and RETE algorithm. 2017 International Conference on Computer Systems, Electronics and Control (ICCSEC), 1392–1396.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Research Questions</span>"
    ]
  },
  {
    "objectID": "06-references.html",
    "href": "06-references.html",
    "title": "References",
    "section": "",
    "text": "Bain, S. K., & Allin, J. D. (2005). Book review: Stanford-binet\nintelligence scales. Journal of Psychoeducational Assessment,\n23(1), 87–95.\n\n\nBaldwin, T. T., Magjuka, R. J., & Loher, B. T. (1991). The perils of\nparticipation: Effects of choice of training on trainee motivation and\nlearning. Personnel Psychology, 44(1), 51–65.\n\n\nBedwell, W. L., Pavlas, D., Heyne, K., Lazzara, E. H., & Salas, E.\n(2012). Toward a taxonomy linking game attributes to learning: An\nempirical study. Simulation & Gaming, 43(6),\n729–760.\n\n\nBerthold, K., Nückles, M., & Renkl, A. (2007). Do learning protocols\nsupport learning strategies and outcomes? The role of cognitive and\nmetacognitive prompts. Learning and Instruction,\n17(5), 564–577.\n\n\nBhagat, K. K., Liou, W.-K., & Chang, C.-Y. (2016). A cost-effective\ninteractive 3D virtual reality system applied to military live firing\ntraining. Virtual Reality, 20(2), 127–140.\n\n\nBissonnette, V., Mirchi, N., Ledwos, N., Alsidieri, G.,\nWinkler-Schwartz, A., & Del Maestro, R. F. (2019). Artificial\nintelligence distinguishes surgical training levels in a virtual reality\nspinal task. The Journal of Bone and Joint Surgery. American\nVolume, 101(23), e127.\n\n\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal,\nP., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. (2020).\nLanguage models are few-shot learners. arXiv Preprint\narXiv:2005.14165.\n\n\nButler, D. (2016). Tomorrow’s world: Technological change is\naccelerating today at an unprecedented speed and could create a world we\ncan barely begin to imagine. Nature, 530(7591),\n398–402.\n\n\nCampion, M. A., Palmer, D. K., & Campion, J. E. (1997). A review of\nstructure in the selection interview. Personnel Psychology,\n50(3), 655–702.\n\n\nCarden, J., Jones, R. J., & Passmore, J. (2022). Defining\nself-awareness in the context of adult development: A systematic\nliterature review. Journal of Management Education,\n46(1), 140–177.\n\n\nChen, F.-Q., Leng, Y.-F., Ge, J.-F., Wang, D.-W., Li, C., Chen, B.,\n& Sun, Z.-L. (2020). Effectiveness of virtual reality in nursing\neducation: Meta-analysis. Journal of Medical Internet Research,\n22(9), e18290.\n\n\nChen, Y.-L., Hsu, C.-C., Lin, C.-Y., & Hsu, H.-H. (2022).\nRobot-assisted language learning: Integrating artificial intelligence\nand virtual reality into english tour guide practice. Education\nSciences, 12(7), 437.\n\n\nCheng, Y., & Wang, S.-H. (2011). Applying a 3D virtual learning\nenvironment to facilitate student’s application ability–the case of\nmarketing. Computers in Human Behavior, 27(1),\n576–584.\n\n\nChoensawat, W., & Sookhanaphibarn, K. (2019). Aircraft recognition\ntraining simulator using virtual reality. 2019 IEEE 8th Global\nConference on Consumer Electronics (GCCE), 47–48.\n\n\nCoates, G. (1992). Program from invisible site—a virtual sho, a\nmultimedia performance work presented by george coates performance\nworks, san francisco, CA, march, 1992.\n\n\nColquitt, J. A., LePine, J. A., & Noe, R. A. (2000). Toward an\nintegrative theory of training motivation: A meta-analytic path analysis\nof 20 years of research. Journal of Applied Psychology,\n85(5), 678.\n\n\nConges, A., Evain, A., Benaben, F., Chabiron, O., & Rebiere, S.\n(2020). Crisis management exercises in virtual reality. 2020 IEEE\nConference on Virtual Reality and 3D User Interfaces Abstracts and\nWorkshops (VRW), 87–92.\n\n\nCummings, J. J., & Bailenson, J. N. (2016). How immersive is enough?\nA meta-analysis of the effect of immersive technology on user presence.\nMedia Psychology, 19(2), 272–309.\n\n\nDewey, J. (1897). My pedagogic creed. EL Kellogg & Company.\n\n\nDewey, J. (1938). The determination of ultimate values or aims through\nantecedent or a priori speculation or through pragmatic or empirical\ninquiry. Teachers College Record, 39(10), 471–485.\n\n\nDi Serio, Á., Ibáñez, M. B., & Kloos, C. D. (2013). Impact of an\naugmented reality system on students’ motivation for a visual art\ncourse. Computers & Education, 68, 586–596.\n\n\nDow, S., Mehta, M., Harmon, E., MacIntyre, B., & Mateas, M. (2007).\nPresence and engagement in an interactive drama. Proceedings of the\nSIGCHI Conference on Human Factors in Computing Systems, 1475–1484.\n\n\nDrawbaugh, M. L., Williams, J. R., et al. (2019). A new look at the\nsupervisor role in performance management. In Feedback at work\n(pp. 9–28). Springer.\n\n\nDubovi, I., Levy, S. T., & Dagan, E. (2017). Now i know how! The\nlearning process of medication administration among nursing students\nwith non-immersive desktop virtual reality simulation. Computers\n& Education, 113, 16–27.\n\n\nDutt, S., Sivaraman, A., Savoy, F., & Rajalakshmi, R. (2020).\nInsights into the growing popularity of artificial intelligence in\nophthalmology. Indian Journal of Ophthalmology, 68(7),\n1339.\n\n\nElo, S., & Kyngäs, H. (2008). The qualitative content analysis\nprocess. Journal of Advanced Nursing, 62(1), 107–115.\n\n\nEscarti, A., & Guzman, J. F. (1999). Effects of feedback on\nself-efficacy, performance, and choice in an athletic task. Journal\nof Applied Sport Psychology, 11(1), 83–96.\n\n\nFereday, J., & Muir-Cochrane, E. (2006). Demonstrating rigor using\nthematic analysis: A hybrid approach of inductive and deductive coding\nand theme development. International Journal of Qualitative\nMethods, 5(1), 80–92.\n\n\nFerro, L. S., Walz, S. P., & Greuter, S. (2013). Towards\npersonalised, gamified systems: An investigation into game design,\npersonality and player typologies. Proceedings of the 9th\nAustralasian Conference on Interactive Entertainment: Matters of Life\nand Death, 1–6.\n\n\nFisher, S. L., & Ford, J. K. (1998). Differential effects of learner\neffort and goal orientation on two learning outcomes. Personnel\nPsychology, 51(2), 397–420.\n\n\nFord, J. K. (2014). Improving training effectiveness in work\norganizations. Psychology Press.\n\n\nFord, J. K. (2020). Learning in organizations: An evidence-based\napproach. Routledge.\n\n\nFord, J. K., Smith, E. M., Weissbein, D. A., Gully, S. M., & Salas,\nE. (1998). Relationships of goal orientation, metacognitive activity,\nand practice strategies with learning outcomes and transfer. Journal\nof Applied Psychology, 83(2), 218.\n\n\nFranzluebbers, A., & Johnsen, K. (2018). Performance benefits of\nhigh-fidelity passive haptic feedback in virtual reality training.\nProceedings of the Symposium on Spatial User Interaction,\n16–24.\n\n\nFreina, L., & Ott, M. (2015). A literature review on immersive\nvirtual reality in education: State of the art and perspectives. The\nInternational Scientific Conference Elearning and Software for\nEducation, 1, 10–1007.\n\n\nFrese, M., Brodbeck, F., Heinbokel, T., Mooser, C., Schleiffenbaum, E.,\n& Thiemann, P. (1991). Errors in training computer skills: On the\npositive function of errors. Human-Computer Interaction,\n6(1), 77–93.\n\n\nGawlik-Kobylińska, M., Maciejewski, P., Lebiedź, J., &\nWysokińska-Senkus, A. (2020). Factors affecting the effectiveness of\nmilitary training in virtual reality environment. Proceedings of the\n2020 9th International Conference on Educational and Information\nTechnology, 144–148.\n\n\nGluck, A., Chen, J., & Paul, R. (2020). Artificial intelligence\nassisted virtual reality warfighter training system. 2020 IEEE\nInternational Conference on Artificial Intelligence and Virtual Reality\n(AIVR), 386–389.\n\n\nGoldstein, I. L., & Ford, J. K. (2002). Training in organizations:\nNeeds assessment. Development, and Evaluation, 4th Ed., Wadsworth,\nBelmont, CA.\n\n\nGong, Y. (2021). Application of virtual reality teaching method and\nartificial intelligence technology in digital media art creation.\nEcological Informatics, 63, 101304.\n\n\nGoodhue, D. L., & Thompson, R. L. (1995). Task-technology fit and\nindividual performance. MIS Quarterly, 213–236.\n\n\nGuffey, C. J., & Helms, M. M. (2001). Effective employee discipline:\nA case of the internal revenue service. Public Personnel\nManagement, 30(1), 111–127.\n\n\nGutierrez-Maldonado, J., Peñaloza, C., Jarne, A., Talarn, A., Andres,\nA., Aguilar, A., & Ferrer, M. (2010). A training program of\ndifferential diagnosis skills based on virtual reality and artificial\nintelligence. 2010 Seventh International Conference on Information\nTechnology: New Generations, 1298–1299.\n\n\nHaenlein, M., & Kaplan, A. (2019). A brief history of artificial\nintelligence: On the past, present, and future of artificial\nintelligence. California Management Review, 61(4),\n5–14.\n\n\nHaque, S., & Srinivasan, S. (2006). A meta-analysis of the training\neffectiveness of virtual reality surgical simulators. IEEE\nTransactions on Information Technology in Biomedicine,\n10(1), 51–58.\n\n\nHassan, S. Z., Salehi, P., Røed, R. K., Halvorsen, P., Baugerud, G. A.,\nJohnson, M. S., Lison, P., Riegler, M., Lamb, M. E., Griwodz, C., et al.\n(2022). Towards an AI-driven talking avatar in virtual reality for\ninvestigative interviews of children. Proceedings of the 2nd\nWorkshop on Games Systems, 9–15.\n\n\nHoward, M. C., & Gutworth, M. B. (2020). A meta-analysis of virtual\nreality training programs for social skill development. Computers\n& Education, 144, 103707.\n\n\nHoward, M. C., Gutworth, M. B., & Jacobs, R. R. (2021). A\nmeta-analysis of virtual reality training programs. Computers in\nHuman Behavior, 121, 106808.\n\n\nHuang, W. (2020). Investigating the novelty effect in virtual\nreality on stem learning [PhD thesis]. Arizona State University.\n\n\nHuang, W., Roscoe, R. D., Johnson-Glenberg, M. C., & Craig, S. D.\n(2021). Motivation, engagement, and performance across multiple virtual\nreality sessions and levels of immersion. Journal of Computer\nAssisted Learning, 37(3), 745–758.\n\n\nHuber, T., Paschold, M., Hansen, C., Wunderling, T., Lang, H., &\nKneist, W. (2017). New dimensions in surgical training: Immersive\nvirtual reality laparoscopic simulation exhilarates surgical staff.\nSurgical Endoscopy, 31, 4472–4477.\n\n\nHwang, G.-J., Chang, C.-C., & Chien, S.-Y. (2022). A motivational\nmodel-based virtual reality approach to prompting learners’ sense of\npresence, learning achievements, and higher-order thinking in\nprofessional safety training. British Journal of Educational\nTechnology, 53(5), 1343–1360.\n\n\nJanzen, H. L., Obrzut, J. E., & Marusiak, C. W. (2004). Test review:\nRoid, GH (2003). Stanford-binet intelligence scales, (SB: V). Itasca,\nIL: Riverside publishing. Canadian Journal of School\nPsychology, 19(1-2), 235–244.\n\n\nJulier, S., King, R., Colbert, B., Durbin, J., & Rosenblum, L.\n(1999). The software architecture of a real-time battlefield\nvisualization virtual environment. Proceedings IEEE Virtual Reality\n(Cat. No. 99CB36316), 29–36.\n\n\nKardong-Edgren, S. S., Farra, S. L., Alinier, G., & Young, H. M.\n(2019). A call to unify definitions of virtual reality. Clinical\nSimulation in Nursing, 31, 28–34.\n\n\nKarl, K. A., O’Leary-Kelly, A. M., & Martocchio, J. J. (1993). The\nimpact of feedback and self-efficacy on performance in training.\nJournal of Organizational Behavior, 14(4), 379–394.\n\n\nKennedy, R. S., Lane, N. E., Berbaum, K. S., & Lilienthal, M. G.\n(1993). Simulator sickness questionnaire: An enhanced method for\nquantifying simulator sickness. The International Journal of\nAviation Psychology, 3(3), 203–220.\n\n\nKim, H. K., Park, J., Choi, Y., & Choe, M. (2018). Virtual reality\nsickness questionnaire (VRSQ): Motion sickness measurement index in a\nvirtual reality environment. Applied Ergonomics, 69,\n66–73.\n\n\nKing, S., Boyer, J., Bell, T., & Estapa, A. (2022). An automated\nvirtual reality training system for teacher-student interaction: A\nrandomized controlled trial. JMIR Serious Games,\n10(4), e41097.\n\n\nKing, S., Estapa, A., Bell, T., & Boyer, J. (2022). Behavioral\nskills training through smart virtual reality: Demonstration of\nfeasibility for a verbal mathematical questioning strategy. Journal\nof Behavioral Education, 1–25.\n\n\nKirkpatrick, D. L. (1979). Techniques for evaluating training programs.\nTraining and Development Journal.\n\n\nKirkpatrick, D. L., & Kirkpatrick, J. D. (1994). Evaluating\nprograms: The four levels. Berrett-Koechler, San Francisco, CA.\n\n\nKiyasseh, D., Laca, J., Haque, T. F., Miles, B. J., Wagner, C., Donoho,\nD. A., Anandkumar, A., & Hung, A. J. (2023). A multi-institutional\nstudy using artificial intelligence to provide reliable and fair\nfeedback to surgeons. Communications Medicine, 3(1),\n42.\n\n\nKlein, H. J., Noe, R. A., & Wang, C. (2006). Motivation to learn and\ncourse outcomes: The impact of delivery mode, learning goal orientation,\nand perceived barriers and enablers. Personnel Psychology,\n59(3), 665–702.\n\n\nKolb, A. Y., & Kolb, D. A. (2009). Experiential learning theory: A\ndynamic, holistic approach to management learning, education and\ndevelopment. The SAGE Handbook of Management Learning, Education and\nDevelopment, 7, 42.\n\n\nKolb, D. A. (2014). Experiential learning: Experience as the source\nof learning and development. FT press.\n\n\nKraiger, K., Ford, J. K., & Salas, E. (1993). Application of\ncognitive, skill-based, and affective theories of learning outcomes to\nnew methods of training evaluation. Journal of Applied\nPsychology, 78(2), 311.\n\n\nKulas, J., DeFabiis, M., Osorio-Duffoo, C., & Russell, M. (2023).\nConstruct and criterion-related validation of the bifactor engagement\nscale. SIOP.\n\n\nKurzweil, R. (2001). The law of accelerating returns. In Alan\nturing: Life and legacy of a great thinker (pp. 381–416). Springer.\n\n\nLe Noury, P., Buszard, T., Reid, M., & Farrow, D. (2021). Examining\nthe representativeness of a virtual reality environment for simulation\nof tennis performance. Journal of Sports Sciences,\n39(4), 412–420.\n\n\nLee, S. H., Sergueeva, K., Catangui, M., & Kandaurova, M. (2017).\nAssessing google cardboard virtual reality as a content delivery system\nin business classrooms. Journal of Education for Business,\n92(4), 153–160.\n\n\nLewin, K. (1951). Field theory in social science: Selected\ntheoretical papers (edited by dorwin cartwright.).\n\n\nLi, J., D’Souza, D., & Du, Y. (2011). Exploring the contribution of\nvirtual worlds to learning in organizations. Human Resource\nDevelopment Review, 10(3), 264–285.\n\n\nLi, J., Mei, X., Wang, J., Xie, B., & Xu, Y. (2020). Simulation\nexperiment teaching for airport fire escape based on virtual reality and\nartificial intelligence technology. 2020 IEEE 2nd International\nConference on Civil Aviation Safety and Information Technology\n(ICCASIT, 1014–1017.\n\n\nLi, M., Sun, Z., Jiang, Z., Tan, Z., & Chen, J. (2020). A virtual\nreality platform for safety training in coal mines with AI and cloud\ncomputing. Discrete Dynamics in Nature and Society,\n2020, 1–7.\n\n\nLiaw, S. Y., Ooi, S. W., Rusli, K. D. B., Lau, T. C., Tam, W. W. S.,\n& Chua, W. L. (2020). Nurse-physician communication team training in\nvirtual reality versus live simulations: Randomized controlled trial on\nteam communication and teamwork attitudes. Journal of Medical\nInternet Research, 22(4), e17279.\n\n\nLiaw, S. Y., Tan, J. Z., Lim, S., Zhou, W., Yap, J., Ratan, R., Ooi, S.\nL., Wong, S. J., Seah, B., & Chua, W. L. (2023). Artificial\nintelligence in virtual reality simulation for interprofessional\ncommunication training: Mixed method study. Nurse Education\nToday, 122, 105718.\n\n\nLin, C.-C., Liu, G.-Z., & Wang, T.-I. (2017). Development and\nusability test of an e-learning tool for engineering graduates to\ndevelop academic writing in english: A case study. Journal of\nEducational Technology & Society, 20(4), 148–161.\n\n\nLiou, H.-H., Yang, S. J., Chen, S. Y., & Tarng, W. (2017). The\ninfluences of the 2D image-based augmented reality and virtual reality\non student learning. Journal of Educational Technology &\nSociety, 20(3), 110–121.\n\n\nLiu, R., Wang, L., Lei, J., Wang, Q., & Ren, Y. (2020). Effects of\nan immersive virtual reality-based classroom on students’ learning\nperformance in science lessons. British Journal of Educational\nTechnology, 51(6), 2034–2049.\n\n\nLuna-Nevarez, C., & McGovern, E. (2021). The rise of the virtual\nreality (VR) marketplace: Exploring the antecedents and consequences of\nconsumer attitudes toward v-commerce. Journal of Internet\nCommerce, 20(2), 167–194.\n\n\nLyu, Z., Li, J., & Wang, B. (2021). AIive: Interactive visualization\nand sonification of neural networks in virtual reality. 2021 IEEE\nInternational Conference on Artificial Intelligence and Virtual Reality\n(AIVR), 251–255.\n\n\nMakransky, G., Borre-Gude, S., & Mayer, R. E. (2019). Motivational\nand cognitive benefits of training in immersive virtual reality based on\nmultiple assessments. Journal of Computer Assisted Learning,\n35(6), 691–707.\n\n\nMakransky, G., Terkildsen, T. S., & Mayer, R. E. (2019). Adding\nimmersive virtual reality to a science lab simulation causes more\npresence but less learning. Learning and Instruction,\n60, 225–236.\n\n\nMatzavela, V., & Alepis, E. (2021). Decision tree learning through a\npredictive model for student academic performance in intelligent\nm-learning environments. Computers and Education: Artificial\nIntelligence, 2, 100035.\n\n\nMcAuley, E., Duncan, T., & Tammen, V. V. (1989). Psychometric\nproperties of the intrinsic motivation inventory in a competitive sport\nsetting: A confirmatory factor analysis. Research Quarterly for\nExercise and Sport, 60(1), 48–58.\n\n\nMcMahan, R. P., Bowman, D. A., Zielinski, D. J., & Brady, R. B.\n(2012). Evaluating display fidelity and interaction fidelity in a\nvirtual reality game. IEEE Transactions on Visualization and\nComputer Graphics, 18(4), 626–633.\n\n\nMichalski, S. C., Szpak, A., Saredakis, D., Ross, T. J., Billinghurst,\nM., & Loetscher, T. (2019). Getting your game on: Using virtual\nreality to improve real table tennis skills. PloS One,\n14(9), e0222351.\n\n\nMilton, S. (1986). A sample size formula for multiple regression\nstudies. Public Opinion Quarterly, 50(1), 112–118.\n\n\nMirchi, N., Bissonnette, V., Yilmaz, R., Ledwos, N., Winkler-Schwartz,\nA., & Del Maestro, R. F. (2020). The virtual operative assistant: An\nexplainable artificial intelligence tool for simulation-based training\nin surgery and medicine. PloS One, 15(2), e0229596.\n\n\nMoglia, A., Ferrari, V., Morelli, L., Ferrari, M., Mosca, F., &\nCuschieri, A. (2016). A systematic review of virtual reality simulators\nfor robot-assisted surgery. European Urology, 69(6),\n1065–1080.\n\n\nMoshell, M. (1993). Three views of virtual reality: Virtual environments\nin the US military. Computer, 26(2), 81–82.\n\n\nMoss, S. E., & Sanchez, J. I. (2004). Are your employees avoiding\nyou? Managerial strategies for closing the feedback gap. Academy of\nManagement Perspectives, 18(1), 32–44.\n\n\nOndrišová, M., Molnár, L., Juhás, G., Juhásová, A., Mažári, J., &\nMladoniczky, M. (2019). Story of artificial intelligence: Research and\npublications behind. 2019 17th International Conference on Emerging\neLearning Technologies and Applications (ICETA), 581–586.\n\n\nOpenAI. (2023). ChatGPT with code interpreter. OpenAI.\n\n\nOrzech, N., Palter, V. N., Reznick, R. K., Aggarwal, R., &\nGrantcharov, T. P. (2012). A comparison of 2 ex vivo training curricula\nfor advanced laparoscopic skills: A randomized controlled trial.\nAnnals of Surgery, 255(5), 833–839.\n\n\nPage, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T.\nC., Mulrow, C. D., Shamseer, L., Tetzlaff, J. M., Akl, E. A., Brennan,\nS. E., et al. (2021). The PRISMA 2020 statement: An updated guideline\nfor reporting systematic reviews. International Journal of\nSurgery, 88, 105906.\n\n\nPan, Z., Cheok, A. D., Yang, H., Zhu, J., & Shi, J. (2006). Virtual\nreality and mixed reality for virtual learning environments.\nComputers & Graphics, 30(1), 20–28.\n\n\nPatel, L. (2010). ASTD state of the industry report 2010.\nAmerican Society for Training & Development.\n\n\nPhillips, J. M., & Gully, S. M. (1997). Role of goal orientation,\nability, need for achievement, and locus of control in the self-efficacy\nand goal–setting process. Journal of Applied Psychology,\n82(5), 792.\n\n\nPiaget, J. (1970). Piaget’s theory (Vol. 1). Wiley New York.\n\n\nPiccione, J., Collett, J., & De Foe, A. (2019). Virtual skills\ntraining: The role of presence and agency. Heliyon,\n5(11), e02583.\n\n\nPopenici, S. A., & Kerr, S. (2017). Exploring the impact of\nartificial intelligence on teaching and learning in higher education.\nResearch and Practice in Technology Enhanced Learning,\n12(1), 1–13.\n\n\nQi, D., Ryason, A., Milef, N., Alfred, S., Abu-Nuwar, M. R., Kappus, M.,\nDe, S., & Jones, D. B. (2021). Virtual reality operating room with\nAI guidance: Design and validation of a fire scenario. Surgical\nEndoscopy, 35, 779–786.\n\n\nRen, S., McKenzie, F. D., Chaturvedi, S. K., Prabhakaran, R., Yoon, J.,\nKatsioloudis, P. J., & Garcia, H. (2015). Design and comparison of\nimmersive interactive learning and instructional techniques for 3D\nvirtual laboratories. Presence, 24(2), 93–112.\n\n\nRodell, J. B., & Colquitt, J. A. (2009). Looking ahead in times of\nuncertainty: The role of anticipatory justice in an organizational\nchange context. Journal of Applied Psychology, 94(4),\n989.\n\n\nRopelato, S., Zünd, F., Magnenat, S., Menozzi, M., & Sumner, R.\n(2018). Adaptive tutoring on a virtual reality driving simulator.\nInternational SERIES on Information Systems and Management in\nCreative Emedia (CreMedia), 2017(2), 12–17.\n\n\nSadeghi Esfahlani, S., Izsof, V., Minter, S., Kordzadeh, A., Shirvani,\nH., & Esfahlani, K. S. (2020). Development of an interactive virtual\nreality for medical skills training supervised by artificial neural\nnetwork. Intelligent Systems and Applications: Proceedings of the\n2019 Intelligent Systems Conference (IntelliSys) Volume 2, 473–482.\n\n\nSalas, E., Tannenbaum, S. I., Kraiger, K., & Smith-Jentsch, K. A.\n(2012). The science of training and development in organizations: What\nmatters in practice. Psychological Science in the Public\nInterest, 13(2), 74–101.\n\n\nSamoili, S., Cobo, M. L., Gómez, E., De Prato, G., Martı́nez-Plumed, F.,\n& Delipetrev, B. (2020). AI watch. Defining artificial\nintelligence. Towards an operational definition and taxonomy of\nartificial intelligence.\n\n\nSchmidt, R. A., & Bjork, R. A. (1992). New conceptualizations of\npractice: Common principles in three paradigms suggest new concepts for\ntraining. Psychological Science, 3(4), 207–218.\n\n\nSchoenfeld, D. A. (1983). Sample-size formula for the\nproportional-hazards regression model. Biometrics, 499–503.\n\n\nSelzer, M. N., Gazcon, N. F., & Larrea, M. L. (2019). Effects of\nvirtual presence and learning outcome using low-end virtual reality\nsystems. Displays, 59, 9–15.\n\n\nServotte, J.-C., Goosse, M., Campbell, S. H., Dardenne, N., Pilote, B.,\nSimoneau, I. L., Guillaume, M., Bragard, I., & Ghuysen, A. (2020).\nVirtual reality experience: Immersion, sense of presence, and\ncybersickness. Clinical Simulation in Nursing, 38,\n35–43.\n\n\nSharma, S. (2020). Improving emergency response training and decision\nmaking using a collaborative virtual reality environment for building\nevacuation. HCI International 2020–Late Breaking Papers: Virtual and\nAugmented Reality: 22nd HCI International Conference, HCII 2020,\nCopenhagen, Denmark, July 19–24, 2020, Proceedings 22, 213–224.\n\n\nSiddaway, A. P., Wood, A. M., & Hedges, L. V. (2019). How to do a\nsystematic review: A best practice guide for conducting and reporting\nnarrative reviews, meta-analyses, and meta-syntheses. Annual Review\nof Psychology, 70, 747–770.\n\n\nSitzmann, T., Bell, B. S., Kraiger, K., & Kanar, A. M. (2009). A\nmultilevel analysis of the effect of prompting self-regulation in\ntechnology-delivered instruction. Personnel Psychology,\n62(4), 697–734.\n\n\nSitzmann, T., & Ely, K. (2010). Sometimes you need a reminder: The\neffects of prompting self-regulation on regulatory processes, learning,\nand attrition. Journal of Applied Psychology, 95(1),\n132.\n\n\nŠkola, F., Rizvić, S., Cozza, M., Barbieri, L., Bruno, F., Skarlatos,\nD., & Liarokapis, F. (2020). Virtual reality with 360-video\nstorytelling in cultural heritage: Study of presence, engagement, and\nimmersion. Sensors, 20(20), 5851.\n\n\nSlater, M., Usoh, M., & Steed, A. (1994). Depth of presence in\nvirtual environments. Presence: Teleoperators & Virtual\nEnvironments, 3(2), 130–144.\n\n\nSlater, M., & Wilbur, S. (1997). A framework for immersive virtual\nenvironments (FIVE): Speculations on the role of presence in virtual\nenvironments. Presence: Teleoperators & Virtual\nEnvironments, 6(6), 603–616.\n\n\nSoderstrom, N. C., & Bjork, R. A. (2015). Learning versus\nperformance: An integrative review. Perspectives on Psychological\nScience, 10(2), 176–199.\n\n\nSong, H., Tucker, A. L., Murrell, K. L., & Vinson, D. R. (2018).\nClosing the productivity gap: Improving worker productivity through\npublic relative performance feedback and validation of best practices.\nManagement Science, 64(6), 2628–2649.\n\n\nSorgenfrei, C., & Smolnik, S. (2016). The effectiveness of\ne-learning systems: A review of the empirical literature on learner\ncontrol. Decision Sciences Journal of Innovative Education,\n14(2), 154–184.\n\n\nSpector, P. E. (2021). Industrial and organizational psychology:\nResearch and practice. John Wiley & Sons.\n\n\nStanica, I., Dascalu, M.-I., Bodea, C. N., & Moldoveanu, A. D. B.\n(2018). VR job interview simulator: Where virtual reality meets\nartificial intelligence for education. 2018 Zooming Innovation in\nConsumer Technologies Conference (ZINC), 9–12.\n\n\nStegeren, J. van, & Myśliwiec, J. (2021). Fine-tuning GPT-2 on\nannotated RPG quests for NPC dialogue generation. Proceedings of the\n16th International Conference on the Foundations of Digital Games,\n1–8.\n\n\nSteuer, J., Biocca, F., Levy, M. R., et al. (1995). Defining virtual\nreality: Dimensions determining telepresence. Communication in the\nAge of Virtual Reality, 33, 37–39.\n\n\nStouten, J., Rousseau, D. M., & De Cremer, D. (2018). Successful\norganizational change: Integrating the management practice and scholarly\nliteratures. Academy of Management Annals, 12(2),\n752–788.\n\n\nSullivan, G. M., & Feinn, R. (2012). Using effect size—or why the p\nvalue is not enough. Journal of Graduate Medical Education,\n4(3), 279–282.\n\n\nTaherdoost, H. (2017). Determining sample size; how to calculate survey\nsample size. International Journal of Economics and Management\nSystems, 2.\n\n\nTakahashi, D. (2022). Available at https://venturebeat.com/games/talespin-raises-20m-to-train-workers-using-spatial-technologies/.\n\n\nTalespin. (2022). Available at https://www.talespin.com/.\n\n\nTang, K.-Y., Chang, C.-Y., & Hwang, G.-J. (2021). Trends in\nartificial intelligence-supported e-learning: A systematic review and\nco-citation network analysis (1998–2019). Interactive Learning\nEnvironments, 1–19.\n\n\nTannenbaum, S. I., Mathieu, J. E., Salas, E., & Cannon-Bowers, J. A.\n(1991). Meeting trainees’ expectations: The influence of training\nfulfillment on the development of commitment, self-efficacy, and\nmotivation. Journal of Applied Psychology, 76(6), 759.\n\n\nTechnologies, U. (2022). Unity. Available at https://unity.com/.\n\n\nTergas, A. I., Sheth, S. B., Green, I. C., Giuntoli, R. L., Winder, A.\nD., Fader, A. N., et al. (2013). A pilot study of surgical training\nusing a virtual robotic surgery simulator. JSLS: Journal of the\nSociety of Laparoendoscopic Surgeons, 17(2), 219.\n\n\nTracey, J. B., Hinkin, T. R., Tannenbaum, S., & Mathieu, J. E.\n(2001). The influence of individual characteristics and the work\nenvironment on varying levels of training outcomes. Human Resource\nDevelopment Quarterly, 12(1), 5–23.\n\n\nTruong, H., Qi, D., Ryason, A., Sullivan, A. M., Cudmore, J., Alfred,\nS., Jones, S. B., Parra, J. M., De, S., & Jones, D. B. (2022). Does\nyour team know how to respond safely to an operating room fire? Outcomes\nof a virtual reality, AI-enhanced simulation training. Surgical\nEndoscopy, 1–9.\n\n\nTüzün, H., & Özdinç, F. (2016). The effects of 3D multi-user virtual\nenvironments on freshmen university students’ conceptual and spatial\nlearning and presence in departmental orientation. Computers &\nEducation, 94, 228–240.\n\n\nUsoh, M., Catena, E., Arman, S., & Slater, M. (2000). Using presence\nquestionnaires in reality. Presence, 9(5), 497–503.\n\n\nVaughan, N., Dubey, V. N., Wainwright, T. W., & Middleton, R. G.\n(2016). A review of virtual reality based training simulators for\northopaedic surgery. Medical Engineering & Physics,\n38(2), 59–71.\n\n\nWang, Y. (2021). Physical education teaching in colleges and\nuniversities assisted by virtual reality technology based on artificial\nintelligence. Mathematical Problems in Engineering,\n2021, 1–11.\n\n\nWinkler-Schwartz, A., Yilmaz, R., Mirchi, N., Bissonnette, V., Ledwos,\nN., Siyar, S., Azarnoush, H., Karlik, B., & Del Maestro, R. (2019).\nMachine learning identification of surgical and operative factors\nassociated with surgical expertise in virtual reality simulation.\nJAMA Network Open, 2(8), e198363–e198363.\n\n\nWitmer, B. G., & Singer, M. J. (1998). Measuring presence in virtual\nenvironments: A presence questionnaire. Presence,\n7(3), 225–240.\n\n\nXie, B., Liu, H., Alghofaili, R., Zhang, Y., Jiang, Y., Lobo, F. D., Li,\nC., Li, W., Huang, H., Akdere, M., et al. (2021). A review on virtual\nreality skill training applications. Frontiers in Virtual\nReality, 2, 645153.\n\n\nYilmaz, R., Winkler-Schwartz, A., Mirchi, N., Reich, A., Christie, S.,\nTran, D. H., Ledwos, N., Fazlollahi, A. M., Santaguida, C., Sabbagh, A.\nJ., et al. (2022). Continuous monitoring of surgical bimanual expertise\nusing deep neural networks in virtual reality simulation. NPJ\nDigital Medicine, 5(1), 54.\n\n\nZhang, Y., Cui, L., Cai, D., Huang, X., Fang, T., & Bi, W. (2023).\nMulti-task instruction tuning of LLaMa for specific scenarios: A\npreliminary study on writing assistance. arXiv Preprint\narXiv:2305.13225.\n\n\nZhang, Y., & Tsai, S.-B. (2021). Application of adaptive virtual\nreality with ai-enabled techniques in modern sports training. Mobile\nInformation Systems, 2021, 1–10.\n\n\nZhou, T. F., Pan, Y. Q., & Huang, L. R. (2017). Research on\npersonalized e-learning based on decision tree and RETE algorithm.\n2017 International Conference on Computer Systems, Electronics and\nControl (ICCSEC), 1392–1396.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "03-methods.html",
    "href": "03-methods.html",
    "title": "4  Methods",
    "section": "",
    "text": "The approach taken for this systematic review was adopted from Page et al. (2021)’s PRISMA guidelines. The entire search process was performed by one researcher in order to fulfill a preliminary examination requirement for a graduate program. Similar to previous systematic reviews (Carden et al., 2022), databases were chosen to provide a comprehensive review of AI-VR training programs. This review utilizes Google Scholar, which includes research from all occupational domains and, thus, is a great tool for finding AI-VR research.\nThe search period was not limited by publication year, but most articles originated after 2019, highlighting the novelty of AI-VR training. The following search terms were used to identify AI-VR training articles on Google Scholar: “virtual reality training ai,” “virtual reality organizational training ai,” “virtual reality AND training AND ai,” and related variations. All searches were performed between March and May of 2023.\nTo be included in the review, articles had to meet three criteria. First, they had to be relevant to organizational or educational training. Second, the training must be conducted using VR technology. Third, an AI component had to be used with the intent of enhancing training. Articles that did not clearly state AI as a focus in the title or abstract were excluded.In adherence to popular methodologies (Siddaway et al., 2019), a PRISMA flowchart was created to show the article selection process (see Figure 1). After scanning and removing articles based on the inclusion criteria, 25 articles were selected.\nEach of the 25 articles was carefully reviewed, and the researcher applied a coding scheme to address the research questions outlined in this review. The researcher manually coded each article based on binary “Yes” or “No” responses to the research questions and identified borderline cases that are further outlined in the results. These explanations provided critical analysis of each article, helping identify deficiencies, omissions, conflicts, strengths, and weaknesses of the selected literature.\n\n\n\n\n\nCarden, J., Jones, R. J., & Passmore, J. (2022). Defining self-awareness in the context of adult development: A systematic literature review. Journal of Management Education, 46(1), 140–177.\n\n\nPage, M. J., McKenzie, J. E., Bossuyt, P. M., Boutron, I., Hoffmann, T. C., Mulrow, C. D., Shamseer, L., Tetzlaff, J. M., Akl, E. A., Brennan, S. E., et al. (2021). The PRISMA 2020 statement: An updated guideline for reporting systematic reviews. International Journal of Surgery, 88, 105906.\n\n\nSiddaway, A. P., Wood, A. M., & Hedges, L. V. (2019). How to do a systematic review: A best practice guide for conducting and reporting narrative reviews, meta-analyses, and meta-syntheses. Annual Review of Psychology, 70, 747–770.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "05-discussion.html",
    "href": "05-discussion.html",
    "title": "6  Discussion",
    "section": "",
    "text": "This systematic literature review aimed to address whether AI-VR research follows learning and development best practices and whether AI adds incremental learning outcomes to VR training.Based on the molar view these results provide, this review presents several guidelines for AI-VR training programs going forward. The aim of these guidelines are to provide researchers of all disciplines with the tools needed to adhere to training best practices. These guidelines are synthesized and displayed in the table below, and build off of previous training research (Salas et al., 2012). We also recommend that researchers use a proper counterfactual (e.g., a control group) and adequate sample size in future studies.\n\n\nTableGuidelines for Future AI-VR Training Research and Adherence to Best PracticesResearch QuestionGuidelines for Future Research1a. Are learning objectives created and clarified to the reader?Create clear learning objectives by including a behavior and criterion. The condition is often implied in AI-VR training programs, but it can be helpful to include.1b. Is the training delivered in a way that builds trainees' belief in their ability to learn and display trained skills (self-efficacy)?Measure self-efficacy directly using a self-efficacy assessment.1c. Does the training encourage trainees to participate in training to learn rather than to appear capable (promotes a learning orientation)?Include effective feedback mechanisms, encourage error making, and create training aspects that focus on learning rather than performance.1d. Does the training engage trainees and build their interest?Measure engagement directly using an engagement assessment.1e. Does the training utilize a valid training strategy and design? This involves providing information, giving demonstrations of good and bad behaviors, allowing opportunities to practice, and providing meaningful feedback.AI-VR training programs should strive to incorporate all of these aspects.1f. Does the training allow trainees to use the same cognitive processes that they will have to in the environment this learning should transfer to?Create immersive training programs that replicate real life tasks and scenarios.1g. Does the training keep trainees' attention by allowing trainees to monitor their progress toward goals?AI-VR training programs can allow trainees' to monitor progress via user interface (UI) elements such as maps and progress bars. AI-VR training programs can also implement checkpoints and endpoints with visual / haptic feedback (success screens, animations, sounds, etc.)1h. Does the training encourage trainees to make errors?Provide instant feedback and additional opportunities for practice to encourage errors.1i. Does the training provide sufficient structure to trainees when allowing them to make decisions about their learning experience?Build game elements that allow trainees to select training courses or use adaptive ai to tailor the sequencing of courses to the trainee's performance. Create scenarios that allow autonomous movement and decision making. Use algorithms that select training scenarios based on participant's training decisions.1j. Does the training simulation increase psychological fidelity (e.g. job-relevant, technology used fits the task)?Ensure that the training programs are job-relevant, have good task-technology fit, and are immersive enough to boost user presence.1k. Does the training use established learning / outcome taxonomies (e.g. affective, cognitive, and/or behavioral indicators)?Always include cognitive and / or behavioral indicators. Include reaction measures beyond engagement and self-efficacy to help provide more information to readers.Note. This table highlights guidelines for achieveing each of the training best practices suggested by Salas (2012).\n\n\nContributions of this article include clarity on the current scope of AI-VR training research, insights into future methodologies for testing the benefits on AI in VR research, and comprehensive guidelines that will bolster future research and minimize confounds. The guidelines presented in this research can be used by educators, practitioners, and for future research development in the field of AI-VR training.\n\n\n\n\nSalas, E., Tannenbaum, S. I., Kraiger, K., & Smith-Jentsch, K. A. (2012). The science of training and development in organizations: What matters in practice. Psychological Science in the Public Interest, 13(2), 74–101.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Discussion</span>"
    ]
  },
  {
    "objectID": "04-results.html",
    "href": "04-results.html",
    "title": "5  Results",
    "section": "",
    "text": "5.1 1. Are the current VR and AI training programs utilizing best practices from the science of training?\nThe top best practices implemented in AI-VR training studies are features that enable trainees to use the same cognitive processes they would in the transfer environment (1f), features that boost psychological fidelity (1j), and the use of valid learning/outcome taxonomies (1k). The least implemented are learning objectives (1a), self-efficacy boosts (1b), increases in engagement and interest (1d), and progress monitoring (1g). The sub-sections below briefly analyze each research question.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#a.-are-learning-objectives-created-and-clarified-to-the-reader",
    "href": "04-results.html#a.-are-learning-objectives-created-and-clarified-to-the-reader",
    "title": "5  Results",
    "section": "5.2 1a. Are learning objectives created and clarified to the reader?",
    "text": "5.2 1a. Are learning objectives created and clarified to the reader?\nIn total, 24% of articles clearly communicated a condition, behavior, and criterion when describing study goals. Hassan et al. (2022) and Winkler-Schwartz et al. (2019) provide clear learning objectives, while 52% of studies did not.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#b.-is-the-training-delivered-in-a-way-that-builds-trainees-belief-in-their-ability-to-learn-and-display-trained-skills-self-efficacy",
    "href": "04-results.html#b.-is-the-training-delivered-in-a-way-that-builds-trainees-belief-in-their-ability-to-learn-and-display-trained-skills-self-efficacy",
    "title": "5  Results",
    "section": "5.3 1b. Is the training delivered in a way that builds trainees’ belief in their ability to learn and display trained skills (self-efficacy)?",
    "text": "5.3 1b. Is the training delivered in a way that builds trainees’ belief in their ability to learn and display trained skills (self-efficacy)?\nOnly 24% of studies had design features that could enhance self-efficacy. A significant number of studies (48%) did not mention self-efficacy or confidence-building measures at all.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#only-24-of-studies-had-design-features-that-could-enhance-self-efficacy.-a-significant-number-of-studies-48-did-not-mention-self-efficacy-or-confidence-building-measures-at-all.",
    "href": "04-results.html#only-24-of-studies-had-design-features-that-could-enhance-self-efficacy.-a-significant-number-of-studies-48-did-not-mention-self-efficacy-or-confidence-building-measures-at-all.",
    "title": "5  Results",
    "section": "5.4 Only 24% of studies had design features that could enhance self-efficacy. A significant number of studies (48%) did not mention self-efficacy or confidence-building measures at all.",
    "text": "5.4 Only 24% of studies had design features that could enhance self-efficacy. A significant number of studies (48%) did not mention self-efficacy or confidence-building measures at all.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#c.-does-the-training-encourage-trainees-to-participate-in-training-to-learn-rather-than-to-appear-capable-promotes-a-learning-orientation",
    "href": "04-results.html#c.-does-the-training-encourage-trainees-to-participate-in-training-to-learn-rather-than-to-appear-capable-promotes-a-learning-orientation",
    "title": "5  Results",
    "section": "5.4 1c. Does the training encourage trainees to participate in training to learn rather than to appear capable (promotes a learning orientation)?",
    "text": "5.4 1c. Does the training encourage trainees to participate in training to learn rather than to appear capable (promotes a learning orientation)?\nIn total, 48% percent of studies successfully fostered a learning orientation, often through AI-guided learning or adjustments based on perceived learning outcomes. However, some studies emphasized performance orientation instead.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#d.-does-the-training-engage-trainees-and-build-their-interest",
    "href": "04-results.html#d.-does-the-training-engage-trainees-and-build-their-interest",
    "title": "5  Results",
    "section": "5.5 1d. Does the training engage trainees and build their interest?",
    "text": "5.5 1d. Does the training engage trainees and build their interest?\nA total of 20% of studies measured engagement or interest levels, while 12% mentioned it as a design focus without measuring it. 68% of studies did not assess engagement at all.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#e.-does-the-training-utilize-a-valid-training-strategy-and-design-this-involves-providing-information-giving-demonstrations-of-good-and-bad-behaviors-allowing-opportunities-to-practice-and-providing-meaningful-feedback.",
    "href": "04-results.html#e.-does-the-training-utilize-a-valid-training-strategy-and-design-this-involves-providing-information-giving-demonstrations-of-good-and-bad-behaviors-allowing-opportunities-to-practice-and-providing-meaningful-feedback.",
    "title": "5  Results",
    "section": "5.6 1e. Does the training utilize a valid training strategy and design? This involves providing information, giving demonstrations of good and bad behaviors, allowing opportunities to practice, and providing meaningful feedback.",
    "text": "5.6 1e. Does the training utilize a valid training strategy and design? This involves providing information, giving demonstrations of good and bad behaviors, allowing opportunities to practice, and providing meaningful feedback.\n60% of studies had a valid training design that incorporated information, practice opportunities, and feedback. Borderline cases lacked important elements like feedback mechanisms.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#f.-does-the-training-allow-trainees-to-use-the-same-cognitive-processes-that-they-will-have-to-in-the-environment-this-learning-should-transfer-to",
    "href": "04-results.html#f.-does-the-training-allow-trainees-to-use-the-same-cognitive-processes-that-they-will-have-to-in-the-environment-this-learning-should-transfer-to",
    "title": "5  Results",
    "section": "5.7 1f. Does the training allow trainees to use the same cognitive processes that they will have to in the environment this learning should transfer to?",
    "text": "5.7 1f. Does the training allow trainees to use the same cognitive processes that they will have to in the environment this learning should transfer to?\n96% of articles recreated real-world scenarios, allowing trainees to engage in the same cognitive processes they would use in their actual environments.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#g.-does-the-training-keep-trainees-attention-by-allowing-trainees-to-monitor-their-progress-toward-goals",
    "href": "04-results.html#g.-does-the-training-keep-trainees-attention-by-allowing-trainees-to-monitor-their-progress-toward-goals",
    "title": "5  Results",
    "section": "5.8 1g. Does the training keep trainees’ attention by allowing trainees to monitor their progress toward goals?",
    "text": "5.8 1g. Does the training keep trainees’ attention by allowing trainees to monitor their progress toward goals?\nOnly 28% of studies allowed trainees to monitor their progress, often through live scoreboards or success screens. 64% of articles lacked elements for monitoring progress.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#h.-does-the-training-encourage-trainees-to-make-errors",
    "href": "04-results.html#h.-does-the-training-encourage-trainees-to-make-errors",
    "title": "5  Results",
    "section": "5.9 1h. Does the training encourage trainees to make errors?",
    "text": "5.9 1h. Does the training encourage trainees to make errors?\n60% of studies encouraged errors, often through repeated trial opportunities and supervised learning approaches. Some studies implied error encouragement but lacked detailed information.[1]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#i.-does-the-training-provide-sufficient-structure-to-trainees-when-allowing-them-to-make-decisions-about-their-learning-experience",
    "href": "04-results.html#i.-does-the-training-provide-sufficient-structure-to-trainees-when-allowing-them-to-make-decisions-about-their-learning-experience",
    "title": "5  Results",
    "section": "5.10 1i. Does the training provide sufficient structure to trainees when allowing them to make decisions about their learning experience?",
    "text": "5.10 1i. Does the training provide sufficient structure to trainees when allowing them to make decisions about their learning experience?\n80% of studies enabled trainees to make decisions about their learning, with AI providing personalized learning paths. The concept of “immersive control” emerged as a new form of learner control in AI-VR environments.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#j.-does-the-training-simulation-increase-psychological-fidelity-e.g.-job-relevant-technology-used-fits-the-task",
    "href": "04-results.html#j.-does-the-training-simulation-increase-psychological-fidelity-e.g.-job-relevant-technology-used-fits-the-task",
    "title": "5  Results",
    "section": "5.11 1j. Does the training simulation increase psychological fidelity (e.g. job-relevant, technology used fits the task)?",
    "text": "5.11 1j. Does the training simulation increase psychological fidelity (e.g. job-relevant, technology used fits the task)?\n96% of training programs boosted psychological fidelity by using job-relevant simulations and technology that fit the task.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#k.-does-the-training-use-established-learning-outcome-taxonomies-e.g.-affective-cognitive-andor-behavioral-indicators",
    "href": "04-results.html#k.-does-the-training-use-established-learning-outcome-taxonomies-e.g.-affective-cognitive-andor-behavioral-indicators",
    "title": "5  Results",
    "section": "5.12 1k. Does the training use established learning / outcome taxonomies (e.g. affective, cognitive, and/or behavioral indicators)?",
    "text": "5.12 1k. Does the training use established learning / outcome taxonomies (e.g. affective, cognitive, and/or behavioral indicators)?\nMost research articles measured variables using elements from established learning / outcome taxonomies (80%). However, 0 studies reference or demonstrate the utilization of any learning / outcome taxonomies. For this reason, these cases were marked at borderline. Table 3 shows a list of evaluation methods used in each study. Based on the table, behavior / skill-based learning outcomes were the most tested. This falls in line with previous theories surrounding VR training (Howard et al., 2021), which state that VR is well-suited to teach skill-outcomes due to its ability to allow trainees to practice by doing.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#are-current-studies-on-ai-enhanced-vr-training-programs-utilizing-a-proper-control-group",
    "href": "04-results.html#are-current-studies-on-ai-enhanced-vr-training-programs-utilizing-a-proper-control-group",
    "title": "5  Results",
    "section": "5.13 2. Are current studies on AI-enhanced VR training programs utilizing a proper control group?",
    "text": "5.13 2. Are current studies on AI-enhanced VR training programs utilizing a proper control group?\nMost studies did not utilize a proper control group to test the incremental effects that AI brings to VR training technologies (92%). Surprisingly, only two of the mentioned studies utilized a proper control group. Qi et al. (2021) and Truong et al. (2022) are the only studies that implement a “VR-only” comparison group. For more information on control groups, see Table 4.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#do-current-studies-on-ai-enhanced-vr-training-programs-have-a-sufficient-number-of-people-to-make-inferences-about-their-effectiveness",
    "href": "04-results.html#do-current-studies-on-ai-enhanced-vr-training-programs-have-a-sufficient-number-of-people-to-make-inferences-about-their-effectiveness",
    "title": "5  Results",
    "section": "5.14 3. Do current studies on AI-enhanced VR training programs have a sufficient number of people to make inferences about their effectiveness?",
    "text": "5.14 3. Do current studies on AI-enhanced VR training programs have a sufficient number of people to make inferences about their effectiveness?\nWhile many studies had adequate sample sizes, they did not meet the prerequisite of comparing AI-VR to “VR-only” trainings. For articles that had adequate sample sizes but did not utilize a proper control group, providing affirmative responses to this question could create misrepresentations in figures. This is because the purpose of this research question is to add substance to the preliminary results of the effects of AI on VR training. For this reason, it was decided to code articles that did not compare AI-VR to VR as “No” for this research question even if their studies included adequate sample sizes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "04-results.html#what-are-the-preliminary-findings-does-adding-ai-to-vr-training-result-in-a-better-experience-for-the-trainee-greater-learning-or-better-on-the-job-performance-than-regular-vr-training",
    "href": "04-results.html#what-are-the-preliminary-findings-does-adding-ai-to-vr-training-result-in-a-better-experience-for-the-trainee-greater-learning-or-better-on-the-job-performance-than-regular-vr-training",
    "title": "5  Results",
    "section": "5.15 4. What are the preliminary findings: Does adding AI to VR training result in a better experience for the trainee, greater learning, or better on the job performance than regular VR training?",
    "text": "5.15 4. What are the preliminary findings: Does adding AI to VR training result in a better experience for the trainee, greater learning, or better on the job performance than regular VR training?\nMost studies do not compare AI-VR to VR, thus making preliminary findings scarce and inconclusive. However, of the articles that do compare AI-VR to VR training programs, AI was found to significantly enhance training outcomes. Qi et al. (2021) found that AI had a moderate effect on performance. Truong et al. (2022) demonstrated that AI doubles the log-odds of passing a trial, indicating improved success rates with AI integration in VR training.\n\n\n\n\nHassan, S. Z., Salehi, P., Røed, R. K., Halvorsen, P., Baugerud, G. A., Johnson, M. S., Lison, P., Riegler, M., Lamb, M. E., Griwodz, C., et al. (2022). Towards an AI-driven talking avatar in virtual reality for investigative interviews of children. Proceedings of the 2nd Workshop on Games Systems, 9–15.\n\n\nQi, D., Ryason, A., Milef, N., Alfred, S., Abu-Nuwar, M. R., Kappus, M., De, S., & Jones, D. B. (2021). Virtual reality operating room with AI guidance: Design and validation of a fire scenario. Surgical Endoscopy, 35, 779–786.\n\n\nTruong, H., Qi, D., Ryason, A., Sullivan, A. M., Cudmore, J., Alfred, S., Jones, S. B., Parra, J. M., De, S., & Jones, D. B. (2022). Does your team know how to respond safely to an operating room fire? Outcomes of a virtual reality, AI-enhanced simulation training. Surgical Endoscopy, 1–9.\n\n\nWinkler-Schwartz, A., Yilmaz, R., Mirchi, N., Bissonnette, V., Ledwos, N., Siyar, S., Azarnoush, H., Karlik, B., & Del Maestro, R. (2019). Machine learning identification of surgical and operative factors associated with surgical expertise in virtual reality simulation. JAMA Network Open, 2(8), e198363–e198363.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "01-background.html#the-role-of-ai-in-vr-training",
    "href": "01-background.html#the-role-of-ai-in-vr-training",
    "title": "2  Background",
    "section": "2.2 The Role of AI in VR Training",
    "text": "2.2 The Role of AI in VR Training\nAI’s capability in learning and development domains has resulted in several creative applications of AI in VR training. Several researchers have employed tactics similar to those used in AI e-learning (AIeL) models, using AI as an assessment tool inside of VR training programs (Bissonnette et al., 2019; Sadeghi Esfahlani et al., 2020; Yilmaz et al., 2022). In addition, AI-generated feedback has received much attention and implementation into VR training (Y.-L. Chen et al., 2022; King et al., 2022; J. Li et al., 2020; Sadeghi Esfahlani et al., 2020). Thanks to advancements in its ability to handle complex tasks, AI has also been incorporated into advanced non-player characters (NPCs) that help provide information to the trainee (M. Li et al., 2020). Researchers have also begun using AI to utilize decision-tree logic that customizes a user’s learning experience (Ropelato et al., 2018). AI is even being used to allow users to learn about and manipulate machine learning algorithms in virtual environments, while having these changes affect real ML algorithms in an external Python environment (Lyu et al., 2021). These are just some of the many ways AI is being used to enhance the VR training experience, further highlighting the versatility that AI brings to this area. With so many inventive uses of AI being implemented into VR, it is no surprise that researchers are enthusiastic about the future of VR training.\n\n\n\n\nBissonnette, V., Mirchi, N., Ledwos, N., Alsidieri, G., Winkler-Schwartz, A., & Del Maestro, R. F. (2019). Artificial intelligence distinguishes surgical training levels in a virtual reality spinal task. The Journal of Bone and Joint Surgery. American Volume, 101(23), e127.\n\n\nChen, F.-Q., Leng, Y.-F., Ge, J.-F., Wang, D.-W., Li, C., Chen, B., & Sun, Z.-L. (2020). Effectiveness of virtual reality in nursing education: Meta-analysis. Journal of Medical Internet Research, 22(9), e18290.\n\n\nChen, Y.-L., Hsu, C.-C., Lin, C.-Y., & Hsu, H.-H. (2022). Robot-assisted language learning: Integrating artificial intelligence and virtual reality into english tour guide practice. Education Sciences, 12(7), 437.\n\n\nFreina, L., & Ott, M. (2015). A literature review on immersive virtual reality in education: State of the art and perspectives. The International Scientific Conference Elearning and Software for Education, 1, 10–1007.\n\n\nHaque, S., & Srinivasan, S. (2006). A meta-analysis of the training effectiveness of virtual reality surgical simulators. IEEE Transactions on Information Technology in Biomedicine, 10(1), 51–58.\n\n\nHoward, M. C., & Gutworth, M. B. (2020). A meta-analysis of virtual reality training programs for social skill development. Computers & Education, 144, 103707.\n\n\nHoward, M. C., Gutworth, M. B., & Jacobs, R. R. (2021). A meta-analysis of virtual reality training programs. Computers in Human Behavior, 121, 106808.\n\n\nKing, S., Boyer, J., Bell, T., & Estapa, A. (2022). An automated virtual reality training system for teacher-student interaction: A randomized controlled trial. JMIR Serious Games, 10(4), e41097.\n\n\nLi, J., Mei, X., Wang, J., Xie, B., & Xu, Y. (2020). Simulation experiment teaching for airport fire escape based on virtual reality and artificial intelligence technology. 2020 IEEE 2nd International Conference on Civil Aviation Safety and Information Technology (ICCASIT, 1014–1017.\n\n\nLi, M., Sun, Z., Jiang, Z., Tan, Z., & Chen, J. (2020). A virtual reality platform for safety training in coal mines with AI and cloud computing. Discrete Dynamics in Nature and Society, 2020, 1–7.\n\n\nLyu, Z., Li, J., & Wang, B. (2021). AIive: Interactive visualization and sonification of neural networks in virtual reality. 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR), 251–255.\n\n\nRopelato, S., Zünd, F., Magnenat, S., Menozzi, M., & Sumner, R. (2018). Adaptive tutoring on a virtual reality driving simulator. International SERIES on Information Systems and Management in Creative Emedia (CreMedia), 2017(2), 12–17.\n\n\nSadeghi Esfahlani, S., Izsof, V., Minter, S., Kordzadeh, A., Shirvani, H., & Esfahlani, K. S. (2020). Development of an interactive virtual reality for medical skills training supervised by artificial neural network. Intelligent Systems and Applications: Proceedings of the 2019 Intelligent Systems Conference (IntelliSys) Volume 2, 473–482.\n\n\nYilmaz, R., Winkler-Schwartz, A., Mirchi, N., Reich, A., Christie, S., Tran, D. H., Ledwos, N., Fazlollahi, A. M., Santaguida, C., Sabbagh, A. J., et al. (2022). Continuous monitoring of surgical bimanual expertise using deep neural networks in virtual reality simulation. NPJ Digital Medicine, 5(1), 54.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  }
]